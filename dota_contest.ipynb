{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отчёт по соревнованию 1: Предскажите вероятность победы команды в Dota 2\n",
    "\n",
    "## Попов Артём Сергеевич ММП ВМК МГУ 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание задания:\n",
    "Dota 2 — многопользовательская компьютерная игра жанра MOBA. Игроки играют между собой матчи. В каждом матче, как правило, участвует 10 человек. Матчи формируются из живой очереди, с учётом уровня игры всех игроков. Перед началом игры игроки автоматически разделяются на две команды по пять человек. Одна команда играет за светлую сторону (The Radiant), другая — за тёмную (The Dire). Цель каждой команды уничтожить главное здание базы противника - трон.\n",
    "\n",
    "Участникам соревнования предлагалась обучающая выборка из матчей, для которых известны все события матча и его результат. В тестовой выборке матчей история обрезана на первых 5 минутах. Участникам сореванования предлагалось предсказать для тестовых матчей вероятность победы команды Radiant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание данных\n",
    "\n",
    "Было несколько разных данных, которые можно было применить для обучения:\n",
    "* Сформированные обучающая и тестовая выборки матчей\n",
    "* \"Сырые\" матчи - словари, из которых можно было взять дополнительную информацию\n",
    "* Таблица характеристик и ролей героев, сделанные по данным с официального сайта Dota2 (дополнительные данные, сформированные Эмилем Каюмовым и мной)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Описание решения (словесное описание и код)\n",
    "\n",
    "(Внимание! В таком виде код никогда не запускался. Во время соревнования код был разбит по разным модулям (для удобства).)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подключение необходимых библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные библиотеки для работы с массивами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as scpst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции для предобработки данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции для измерения качества модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции, реализующие алгоритмы машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции для работы с \"сырыми матчами\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Мешки слов по предметам и способностям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В информации, содержащейся в \"сырых\" матчах и неучтённой в обучающей выборке, показались важными два компонента:\n",
    "1. Информация о предметах героев (в обучающей выборке была только информация о количестве предметов)\n",
    "2. Информация о выбранных улучшениях способностей героев\n",
    "\n",
    "По этим данным были составлены мешки предметов и мешки способностей для каждой из команд (у каждой команды свой мешок)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_events(events, time_point=60*5):\n",
    "    return [event for event in events if event['time'] <= time_point]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bags(name_file):\n",
    "    item_data = pd.DataFrame(np.zeros((97230, 11)),\n",
    "                             columns=['match_id'] + ['r' + str(i) + '_items' for i in range(1, 6)] +\n",
    "                             ['d' + str(i) + '_items' for i in range(6, 11)])\n",
    "    ability_data = pd.DataFrame(np.zeros((97230, 11)),\n",
    "                                columns=['match_id'] + ['r' + str(i) + '_ability' for i in range(1, 6)] +\n",
    "                                ['d' + str(i) + '_ability' for i in range(6, 11)])\n",
    "    j = -1\n",
    "    with bz2.BZ2File(name_file) as matches_file:\n",
    "        for line in matches_file:\n",
    "            j += 1\n",
    "            match = json.loads(line)\n",
    "\n",
    "            item_data['match_id'].iloc[j] = match['match_id']\n",
    "            ability_data['match_id'].iloc[j] = match['match_id']\n",
    "\n",
    "            for i in range(0, 10):\n",
    "                if i < 5: \n",
    "                    item_data['r' + str(i + 1) + '_items'].iloc[j] = ' '.join(map(lambda x: str(x['item_id']),\n",
    "                                                                    filter_events(match['players'][i]['purchase_log'])))\n",
    "\n",
    "                    ability_data['r' + str(i + 1) + '_ability'].iloc[j] = ' '.join(map(lambda x: str(x['ability']),\n",
    "                                                                    filter_events(match['players'][i]['ability_upgrades'])))\n",
    "\n",
    "                else:\n",
    "                    item_data['d' + str(i + 1) + '_items'].iloc[j] = ' '.join(map(lambda x: str(x['item_id']),\n",
    "                                                                    filter_events(match['players'][i]['purchase_log'])))\n",
    "\n",
    "                    ability_data['d' + str(i + 1) + '_ability'].iloc[j] = ' '.join(map(lambda x: str(x['ability']),\n",
    "                                                                    filter_events(match['players'][i]['ability_upgrades'])))\n",
    "\n",
    "\n",
    "            if j % 10000 == 0:\n",
    "                print(j)\n",
    "    item_data = item_data.sort(['match_id'])\n",
    "    ability_data = ability_data.sort(['match_id'])\n",
    "    \n",
    "    item_data.loc[np.where(item_data.isnull())] = 'nan'\n",
    "    ability_data.loc[np.where(ability_data.isnull())] = 'nan'\n",
    "    \n",
    "    item_data['r_items'] = item_data['r1_items'] + ' ' + item_data['r2_items'] + ' ' + item_data['r3_items'] + ' ' +\n",
    "                           item_data['r4_items'] + ' ' + item_data['r5_items']\n",
    "    item_data['d_items'] = item_data['d6_items'] + ' '+ item_data['d7_items'] + ' ' + item_data['d8_items'] + ' ' +\n",
    "                           item_data['d9_items'] + ' ' + item_data['d10_items']\n",
    "    item_data = item_data[['match_id', 'r_items', 'd_items']]\n",
    "    \n",
    "    \n",
    "    ability_data['r_ability'] = ability_data['r1_ability'] + ' ' + ability_data['r2_ability'] + ' ' + ability_data['r3_ability'] +\n",
    "                                ' ' + ability_data['r4_ability'] + ' ' + ability_data['r5_ability']\n",
    "    ability_data['d_ability'] = ability_data['d6_ability'] + ' ' + ability_data['d7_ability'] + ' ' + ability_data['d8_ability'] +\n",
    "                                ' ' + ability_data['d9_ability'] + ' ' + ability_data['d10_ability']\n",
    "    ability_data = ability_data[['match_id', 'r_ability', 'd_ability']]\n",
    "\n",
    "    return item_data, ability_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item_data, ability_data = get_bags('data/matches.jsonlines.bz2')\n",
    "item_data_test, ability_data_test = get_bags('data/matches_test.jsonlines.bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мешок по предметам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(min_df=1)\n",
    "count_vec.fit(item_data['r_items'])\n",
    "r_train = count_vec.transform(item_data['r_items'])\n",
    "r_test = count_vec.transform(item_data_test['r_items'])\n",
    "\n",
    "count_vec.fit(item_data['d_items'])\n",
    "d_train = count_vec.transform(item_data['d_items'])\n",
    "d_test = count_vec.transform(item_data_test['d_items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('data/items_train.npy', np.hstack((r_train.toarray(), d_train.toarray())))\n",
    "np.save('data/items_test.npy', np.hstack((r_test.toarray(), d_test.toarray())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мешок по способностям:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(min_df=1)\n",
    "count_vec.fit(ability_data['r_ability'])\n",
    "r_train = count_vec.transform(ability_data['r_ability'])\n",
    "r_test = count_vec.transform(ability_data_test['r_ability'])\n",
    "\n",
    "count_vec.fit(ability_data['d_ability'])\n",
    "d_train = count_vec.transform(ability_data['d_ability'])\n",
    "d_test = count_vec.transform(ability_data_test['d_ability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('data/ability_train.npy', np.hstack((r_train.toarray(), d_train.toarray())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('data/ability_test.npy', np.hstack((r_test.toarray(), d_test.toarray())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции, для последующего добавления мешков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_item_bag(data_train, data_test):\n",
    "    item_bag_train = np.load('data/items_train.npy')\n",
    "    item_bag_test = np.load('data/items_test.npy')\n",
    "    data_train = pd.concat([data_train,\n",
    "                            pd.DataFrame(item_bag_train, columns = ['it_bag' + str(i) for i in range(item_bag_train.shape[1])])],\n",
    "                           axis=1)\n",
    "    data_test = pd.concat([data_test,\n",
    "                           pd.DataFrame(item_bag_test, columns = ['it_bag' + str(i) for i in range(item_bag_train.shape[1])])],\n",
    "                          axis=1)\n",
    "    return data_train, data_test\n",
    "    \n",
    "def add_ability_bag(data_train, data_test):\n",
    "    ability_bag_train = np.load('data/ability_train.npy')\n",
    "    ability_bag_test = np.load('data/ability_test.npy')\n",
    "    data_train = pd.concat([data_train,\n",
    "                            pd.DataFrame(ability_bag_train, \n",
    "                                         columns = ['ab_bag' + str(i) for i in range(ability_bag_train.shape[1])])],\n",
    "                           axis=1)\n",
    "    data_test = pd.concat([data_test,\n",
    "                           pd.DataFrame(ability_bag_test,\n",
    "                                        columns = ['ab_bag' + str(i) for i in range(ability_bag_train.shape[1])])],\n",
    "                          axis=1)\n",
    "    return data_train, data_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Синергия и антисинергия героев\n",
    "\n",
    "В статье http://cseweb.ucsd.edu/~jmcauley/cse255/reports/fa15/018.pdf предложен способ учёта взаимодействия между парами героев. Авторы статьи предлагают сделать два дополнительных признака: синергию и антисинергию.\n",
    "\n",
    "Необходимо подсчитать для всех героев по обучающей выборке характеристики:\n",
    "* $S_{ij} $ - количество раз, когда i-ый и j-ый герой были в одной команде и победили\n",
    "* $C_{ij} $ - количество раз, когда команда, в которой был i-ый герой, победила команду, в которой был j-ый герой\n",
    "\n",
    "Тогда:\n",
    "* Синергия: $\\; \\sum_{i, j \\in radiant}S_{ij} - \\sum_{i, j \\in dire}S_{ij}$\n",
    "* Антисинергия: $\\; \\sum_{i, j \\in dire}C_{ij} - \\sum_{i, j \\in dire}C_{ij}$\n",
    "\n",
    "Если использовать этот подход, эти два признака приводят к сильному переобучению модели. \n",
    "Можно воспользоваться подходом, похожим на тот, что применяется при использовании счётчиков. \n",
    "Разобьём выборку на несколько фолдов, для каждого фолда синергия и антисинергия считается по всем остальным фолдам.\n",
    "Синергия и антисинергия тестовой выборке считается по обучающей выборке. Выбранное число фолдов - 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_rating(data):\n",
    "    N = 113 # heroes\n",
    "    # calculate each hero-pair synergy and antisynergy\n",
    "    synergy = np.zeros((N,N))     # sum of wins in matches played together\n",
    "    antisynergy = np.zeros((N,N)) # sum of wins when played against\n",
    "    matchcounts = np.zeros((N,N)) # count of matches played together\n",
    "    matchcounta = np.zeros((N,N)) # count of matches played against\n",
    "    \n",
    "    for match_counter, match_id in enumerate(data.index):\n",
    "        #synergy when both heroes in win team\n",
    "        winteam = 'r' if data.ix[match_id, 'radiant_win'] == 1 else 'd'\n",
    "        looseteam = 'd' if winteam =='r' else 'r'\n",
    "        pind     = [0] *5 #player indexes    \n",
    "        antipind = [0] *5 # looser indicies\n",
    "        # get indexes of players in each tem\n",
    "        for i in range(5):\n",
    "            pind[i] = data.ix[match_id, winteam+'%d_hero'%(i+1)]-1\n",
    "        for i in range(5):\n",
    "            antipind[i] = data.ix[match_id, looseteam+'%d_hero'%(i+1)]-1\n",
    "        # accumulate synergy of pairs\n",
    "        for i in range(5):\n",
    "            for j in range(i+1,5):\n",
    "                synergy[pind[i], pind[j]] +=1\n",
    "                synergy[pind[j], pind[i]] +=1\n",
    "        # accumulate match counter for playing together\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                matchcounts[pind[i], pind[j]] +=1 #together and win\n",
    "                matchcounts[antipind[i], antipind[j]] +=1 # together and loose\n",
    "                \n",
    "        #antisynergy when hero i in winteam while hero j in loose team\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                antisynergy[pind[i], antipind[j]] +=1\n",
    "                matchcounta[pind[i], antipind[j]] +=1\n",
    "                matchcounta[antipind[j], pind[i]] +=1\n",
    "            \n",
    "    # normalize\n",
    "    synergyrate = np.zeros((N,N))\n",
    "    antisynergyrate = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if matchcounts[i,j] !=0:\n",
    "                synergyrate[i,j] = synergy[i,j]/matchcounts[i,j] \n",
    "            else:\n",
    "                synergyrate[i,j] = 0.5  \n",
    "            if matchcounta[i,j] !=0:\n",
    "                antisynergyrate[i,j] = antisynergy[i,j]/ matchcounta[i,j]\n",
    "            else:\n",
    "                antisynergyrate[i,j] = 0.5      \n",
    "\n",
    "    return synergyrate, antisynergyrate\n",
    "\n",
    "\n",
    "def add_synergy(data, synergyrate, antisynergyrate):\n",
    "    # calculate aggreagtes synergy and antisyn    \n",
    "    syn = np.zeros(len(data))\n",
    "    antisyn = np.zeros(len(data))\n",
    "    for match_counter, match_id in enumerate(data.index):\n",
    "        rind = [0] *5 #radiant indicies    \n",
    "        dind = [0] *5 # dire indicies\n",
    "        # get indexes of players in each team\n",
    "        for i in range(5):\n",
    "            rind[i] = data.ix[match_id, 'r%d_hero'%(i+1)]-1\n",
    "        for i in range(5):\n",
    "            dind[i] = data.ix[match_id, 'd%d_hero'%(i+1)]-1\n",
    "        # accumulate synergy of radiants minus synergy of dires\n",
    "        # + radiants synergy\n",
    "        for i in range(5):\n",
    "            for j in range(i+1,5):\n",
    "                syn[match_counter] += synergyrate[rind[i], rind[j]]\n",
    "        # - dire synergy\n",
    "        for i in range(5):\n",
    "            for j in range(i+1,5):\n",
    "                syn[match_counter] -= synergyrate[dind[i], dind[j]]\n",
    "        # accumulate antisynergy\n",
    "        for i in range(5):\n",
    "            for j in range(5):\n",
    "                antisyn[match_counter] += antisynergyrate[rind[i], dind[j]] \n",
    "                \n",
    "    data['synergy'] = syn\n",
    "    data['antisynergy'] = antisyn\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess\n",
    "data_train = pd.read_csv('data/features.csv')\n",
    "data_train.fillna(0, inplace=True)\n",
    "\n",
    "data_test = pd.read_csv('data/features_test.csv')\n",
    "data_test.fillna(0, inplace=True)\n",
    "\n",
    "### для теста\n",
    "synergyrate, antisynergyrate = calc_rating(data_train)\n",
    "data_test = add_synergy(data_test, synergyrate, antisynergyrate)\n",
    "\n",
    "### для трэйна\n",
    "data_train['synergy'] = 0\n",
    "data_train['antisynergy'] = 0\n",
    "\n",
    "cv = KFold(data_train.shape[0], n_folds=30)\n",
    "\n",
    "for ind_train, ind_test in cv:\n",
    "    synergyrate, antisynergyrate = calc_rating(data_train.loc[ind_train, :])\n",
    "    data_train.loc[ind_test, :] = add_synergy(data_train.loc[ind_test, :], synergyrate, antisynergyrate)\n",
    "    \n",
    "data_train.to_csv('data/new_features.csv')\n",
    "data_test.to_csv('data/new_features_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Роли героев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из всей таблицы с дополнительными данными были выбраны столбцы отвечающие принадлежности героев к:\n",
    "* определённой роли в Dota2 (Carry, Nuker и т.д.)\n",
    "* типу атаки (ближний или дальний бой)\n",
    "* главной характеристики (сила, ловкость, интеллект)\n",
    "\n",
    "Для каждой команды были подсчитаны статистики: сколько в этой команде героев какого типа (т.е. сколько в команде Carry, сколько героев ближнего боя, сколько силачей и т.д.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_hero = pd.read_csv('heroes_db.csv', index_col=0)\n",
    "data = pd.read_csv('data/new_features.csv')\n",
    "test = pd.read_csv('data/new_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_super_new_features(data, data_hero):\n",
    "    for string in [u'Carry', u'Disabler', u'Lane_support', u'Initiator', u'Jungler', u'Support', u'Durable', u'Pusher',\n",
    "                   u'Nuker', u'Escape', u'Melee', u'Ranged', u'Strength', u'Intelligence', u'Agility']:\n",
    "        for team in ['r', 'd']:\n",
    "            num_hero = [team + str(i) + '_hero' for i in range(2, 6)]\n",
    "            data[team + '_' + string] = data_hero[string][data[team + '1_hero']].values\n",
    "            for str_hero in num_hero:\n",
    "                data[team + '_' + string] += data_hero[string][data[str_hero]].values\n",
    "                        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = add_super_new_features(data, data_hero)\n",
    "test = add_super_new_features(test, data_hero)\n",
    "\n",
    "data.to_csv('data_with_super_features.csv', index='Unnamed: 0')\n",
    "test.to_csv('test_with_super_features.csv', index='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One-hot-encoding героев\n",
    "Для успешной работы алгоритма необходимо закодировать информацию о том, какие герои были в каких командах. Был выбран способ предложенный в https://github.com/esokolov/ml-course-msu/blob/master/ML15-spring/contests/contest01-dota/contest01-dota-statement.ipynb: one-hot-encoding героев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoding(encode, data):\n",
    "    arr1 = encode.transform(data.r1_hero.values.reshape(-1, 1)).toarray()\n",
    "    arr2 = encode.transform(data.r2_hero.values.reshape(-1, 1)).toarray()\n",
    "    arr3 = encode.transform(data.r3_hero.values.reshape(-1, 1)).toarray()\n",
    "    arr4 = encode.transform(data.r4_hero.values.reshape(-1, 1)).toarray()\n",
    "    arr5 = encode.transform(data.r5_hero.values.reshape(-1, 1)).toarray()\n",
    "    arr = arr1 + arr2 + arr3 + arr4 + arr5\n",
    "    \n",
    "    \n",
    "    arr1 = encode.transform(data.d1_hero.values.reshape(-1, 1)).toarray()\n",
    "    arr2 = encode.transform(data.d2_hero.values.reshape(-1, 1)).toarray()\n",
    "    arr3 = encode.transform(data.d3_hero.values.reshape(-1, 1)).toarray()\n",
    "    arr4 = encode.transform(data.d4_hero.values.reshape(-1, 1)).toarray()\n",
    "    arr5 = encode.transform(data.d5_hero.values.reshape(-1, 1)).toarray()\n",
    "    arr = arr - (arr1 + arr2 + arr3 + arr4 + arr5)\n",
    "    \n",
    "    dataframe = pd.DataFrame(arr, columns=[str('hero_') + str(n) for n in range(arr.shape[1])])\n",
    "    dataframe.index.name = 'match_id'\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Изменение основных признаков\n",
    "\n",
    "Для улучшения модели был использован следующий приём: признаки, относящиеся к героям, были отсортированы внутри каждой команды.\n",
    "Было сделано one-hot кодирование для признака lobby type. Был создан дополнительный признак отношение смертей к убийствам. Было сделано небольшое преобразование над признаками, отвечающими количеству смертей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_missing_values(imputer, data):\n",
    "    temp = imputer.transform(data)\n",
    "    data.iloc[:, :] = temp\n",
    "    return data\n",
    "\n",
    "def data_prepare(data_train, data_test):\n",
    "    new_data_train = pd.DataFrame()\n",
    "    new_data_test = pd.DataFrame()\n",
    "    \n",
    "    y_train = (data_train.radiant_win.ravel() - 0.5) * 2\n",
    "    \n",
    "    index_answer = ['radiant_win', 'duration', 'tower_status_radiant', 'tower_status_dire',\n",
    "                    'barracks_status_dire', 'barracks_status_radiant']\n",
    "    index_heroes = ['r' + str(i) + '_hero' for i in range(1, 6)]\n",
    "    index_other = ['match_id', 'start_time']\n",
    "    \n",
    "    \n",
    "    ### missing values\n",
    "    imp = Imputer(strategy='median')\n",
    "    imp.fit(data_train.drop(index_answer, axis=1))\n",
    "    \n",
    "    new_data_train = delete_missing_values(imp, data_train.drop(index_answer, axis=1))\n",
    "    new_data_test = delete_missing_values(imp, data_test)\n",
    "    \n",
    "    ### One-Hot-Encoding\n",
    "    encoder = OneHotEncoder()\n",
    "    encoder.fit(data_train.r1_hero.values.reshape(-1, 1))\n",
    "    #train_encode = encoding(encoder, data_train)\n",
    "    new_data_train = pd.concat([new_data_train, encoding(encoder, data_train)], axis=1)\n",
    "    new_data_test = pd.concat([new_data_test, encoding(encoder, data_test)], axis=1)\n",
    "    \n",
    "    \n",
    "    encoder2 = OneHotEncoder()\n",
    "    encoder2.fit(data_train.lobby_type.values.reshape(-1, 1))\n",
    "    \n",
    "    new_data_train = pd.concat([new_data_train,\n",
    "                                pd.DataFrame(encoder2.transform(data_train.lobby_type.values.reshape(-1, 1)).toarray())],\n",
    "                               axis=1)\n",
    "    new_data_test = pd.concat([new_data_test,\n",
    "                               pd.DataFrame(encoder2.transform(data_test.lobby_type.values.reshape(-1, 1)).toarray())],\n",
    "                              axis=1)\n",
    "\n",
    "    ### исключаем плохие признаки\n",
    "    \n",
    "    index_total = index_heroes + index_other\n",
    "    new_data_train = new_data_train.drop(index_total, axis=1)\n",
    "    new_data_test = new_data_test.drop(index_total, axis=1)\n",
    "    \n",
    "    \n",
    "    ### добавление фичей\n",
    "    new_data_train = add_features(new_data_train)\n",
    "    new_data_test = add_features(new_data_test)\n",
    "    \n",
    "    ### скейлинг\n",
    "    scale = StandardScaler()\n",
    "    scale.fit(new_data_train)\n",
    "    new_data_train = pd.DataFrame(scale.transform(new_data_train), columns=new_data_train.columns)\n",
    "    new_data_test = pd.DataFrame(scale.transform(new_data_test), columns=new_data_train.columns)\n",
    "    return new_data_train.drop(new_data_train.columns[:76], axis=1),\n",
    "           y_train, new_data_test.drop(new_data_train.columns[:76], axis=1)\n",
    "\n",
    "def add_features(data):\n",
    "    for i in range(1, 6):\n",
    "        data['r' + str(i) + '_prob_ratio'] = (data['r' + str(i) + '_deaths']) / (data['r' + str(i) + '_kills'] + 1)\n",
    "        data['d' + str(i) + '_prob_ratio'] = (data['d' + str(i) + '_deaths']) / (data['d' + str(i) + '_kills'] + 1)\n",
    "                \n",
    "    for string_feat in ['xp','level', 'gold', 'lh', 'kills', 'deaths', 'items']:\n",
    "        new_feat = np.zeros(data.shape[0])\n",
    "        r_feat = ['r' + str(i) + '_' + string_feat for i in range(1, 6)]\n",
    "        d_feat = ['d' + str(i) + '_' + string_feat for i in range(1, 6)]\n",
    "        \n",
    "        data['r_' + string_feat + '_total'] = np.sum(data[r_feat], axis=1)\n",
    "        data['d_' + string_feat + '_total'] = np.sum(data[d_feat], axis=1)\n",
    "        \n",
    "        \n",
    "        temp1 = np.sort(data[r_feat], axis=1)\n",
    "        temp2 = np.sort(data[d_feat], axis=1)\n",
    "        \n",
    "        for i in range(1, 6):\n",
    "            data['r_' + string_feat + '_max' + str(i)] = temp1[:, i - 1]\n",
    "            data['d_' + string_feat + '_max' + str(i)] = temp2[:, i - 1]\n",
    "            \n",
    "            if string_feat == 'deaths':\n",
    "                data['r_' + string_feat + '_max' + str(i)] = temp1[:, i - 1] ** 1.1\n",
    "                data['d_' + string_feat + '_max' + str(i)] = temp2[:, i - 1] ** 1.1\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Применение алгоритмов\n",
    "Для решения поставленной задачи был выбран алгоритм - логистическая регрессия. На финальном этапе решения задачи было решено составить ансамбль из логистической регрессии и градиентного бустинга. Для бустинга использовалась калибировка вероятностей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для логистической регрессии были использованы следующие наборы признаков:\n",
    "\n",
    "* преобразованная обучающая выборка\n",
    "* синергия и антисинергия\n",
    "* мешок предметов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = 'data/new_features.csv'\n",
    "data_train = pd.read_csv(train_path)\n",
    "\n",
    "test_path = 'data/new_features_test.csv'\n",
    "data_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test = data_prepare(data_train, data_test)\n",
    "X_train, X_test = add_item_bag(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression()\n",
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred1 = clf1.predict_proba(X_test)[:, 1]\n",
    "preds_csv = pd.DataFrame({\"match_id\": data_test['match_id'], \"radiant_win\": pred1})\n",
    "preds_csv = preds_csv.set_index(\"match_id\")\n",
    "preds_csv.to_csv('preds/log_reg_predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Градиентный бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для градиентного бустинга были использованы следующие наборы признаков:\n",
    "\n",
    "* преобразованная обучающая выборка\n",
    "* синергия и антисинергия\n",
    "* мешок предметов\n",
    "* мешок способностей\n",
    "* роли героев (доп. данные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = 'data_with_super_features.csv'\n",
    "data_train = pd.read_csv(train_path)\n",
    "\n",
    "test_path = 'test_with_super_features.csv'\n",
    "data_test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test = data_prepare(data_train, data_test)\n",
    "X_train, X_test = add_item_bag(X_train, X_test)\n",
    "X_train, X_test = add_ability_bag(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm = CalibratedClassifierCV(base_estimator=xgb.XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.2, nthread=2))\n",
    "gbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred1 = gbm.predict_proba(X_test)[:, 1]\n",
    "preds_csv = pd.DataFrame({\"match_id\": data_test['match_id'], \"radiant_win\": pred1})\n",
    "preds_csv = preds_csv.set_index(\"match_id\")\n",
    "preds_csv.to_csv('preds/gbm_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ансамбль\n",
    "\n",
    "Для итоговой модели предсказания были усреднены с весами 0.65 (лог. регрессия) и 0.35(бустинг)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_csv = pd.DataFrame({\"match_id\": data_test['match_id'], \"radiant_win\": 0.65 * pred1 + 0.35 * pred2})\n",
    "preds_csv = preds_csv.set_index(\"match_id\")\n",
    "preds_csv.to_csv('preds/ansamble_3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 0.76490 - public (50% выборки) \n",
    "* 0.76455 - private (50% выборки)\n",
    "* 0.76474 - вся выборка\n",
    "\n",
    "В целом, можно сказать, что задача труднорешаема. Пять первых минут матча Dota дают очень мало информации об игроках, чтобы сделать хорошее предсказание. ROC-AUC в 0.75 достигается только с помощью one-hot-encoding героев, остальные навороты (а их было немало) позволили улучшить начальный результат примерно на 1.5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
